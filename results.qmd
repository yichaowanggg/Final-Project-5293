# Results of Linear and Non-linear Models

## Linear Model
We now move to construct a predictive model after simulating our dataset with important behavioral characteristics connected to online buying. Ou response variable buy being binary (1 = purchased, 0 = no purchase), we estimate the probability of purchase as a function of the six explanatory variables using a Logistic Regression model. It is a suitable option that models the log-odds of purchase as a linear mixture of the six characteristics, given that the outcome variable is binary. The coefficient predicted by the logistic model here could vary from the "ground truth" coefficients we used to simulated the dataset. Added random noise and sample variation cause this difference, which more genuinely represents uncertainty in a real-world data. We estimate how well the model recovers the underlying data-generating process by contrasting the projected coefficients with the known ground truth.

Before the modelling process, install all packages:
```{r, echo=TRUE, results='hide', message = FALSE, warning = FALSE}
# packages
library(ggplot2)
library(tidyverse)
library(broom)
library(dplyr)
library(tidyr)
library(pdp)
library(lime)
library(randomForest)
library(vip)
```

And load the dataset we simulated before:
```{r, echo=TRUE, results='hide'}
set.seed(5293)
n <- 500

# Generate the features for the dataset
browsing_time <- rnorm(n, mean = 3, sd = 1)               # hours
category_count <- rpois(n, lambda = 4)                    # integer count
clicked_ad <- rbinom(n, 1, prob = 0.35)                   # binary
items_in_cart <- rpois(n, lambda = 2)                     # integer count
device_type <- rbinom(n, 1, prob = 0.6)                   # 0 = desktop, 1 = mobile
previous_purchases <- rbinom(n, 1, prob = 0.25)           # binary
noise <- rnorm(n, 0, 0.5)

# Simulate outcome
logit <- -1 + 
  0.8 * browsing_time - 
  0.6 * category_count + 
  1.2 * clicked_ad + 
  0.5 * items_in_cart + 
  0.4 * previous_purchases +
  0.3 * device_type +
  noise

p <- 1 / (1 + exp(-logit))
purchase <- rbinom(n, 1, p)

# Assemble data frame
sim_data <- data.frame(
  browsing_time,
  category_count,
  clicked_ad,
  items_in_cart,
  device_type = factor(device_type, levels = c(0, 1), labels = c("desktop", "mobile")),
  previous_purchases,
  purchase
)
#head(sim_data)
```

### Fit the Linear Model (logistic regression)
```{r}
sim_data <- sim_data
# fit the logistic regression model
log_model <- glm(purchase ~ ., data = sim_data, family = "binomial")

summary(log_model)
```

Based on the logistic model we generated, the summary result shows that statistically significant predictors include `browsing_time`, `category_count`, `clicked_ad`, `items_in_cart`, and `previous_purchases`. This means that these five feature have important impact in purchase behavior. However, `device_type` is not significant (p = 0.764), indicating that switching from desktop to mobile does not have a strong independent effect on the likelihood of purchase in this model. Signs of coefficients match the logic of the simulation (positive for most predictors, negative for category count), though values differ slightly due to added noise. Additionally, the residual deviance of 438.31, compared to the null deviance of 683.31, suggests that the model explains a substantial portion of the variability in the outcome. By adding these six predictors, the deviance reduced from 683.31 to 438.31, means that our features signigicantly improve the model's predicting ability. The overall logistic model at this step can be written as:

\begin{align}
\log\left(\frac{P(\text{purchase} = 1)}{1 - P(\text{purchase} = 1)}\right) &= 
-1.1147 + 0.8417 \cdot \text{browsing\_time} \\
&\quad - 0.7234 \cdot \text{category\_count} 
+ 1.6193 \cdot \text{clicked\_ad} \\
&\quad + 0.5856 \cdot \text{items\_in\_cart} 
+ 0.0721 \cdot \text{device\_type}_{\text{mobile}} \\
&\quad + 0.7629 \cdot \text{previous\_purchases}
\end{align}



### Added Variable Plots

To further analysis the contribution of each individual predictors, we use the Added Variable Plot (AVP) to more fully considering the influences of other variables. By graphing the response residuals (after regressing out the other predictors) against the predictor residuals (after regressing it out from the other predictors as well), this diagnostic tool shows the partial link between the outcome and a chosen predictor.

```{r}
library(tidyverse)
library(broom)

# numeric predictors
numeric_vars <- sim_data %>%
  select(where(is.numeric)) %>%
  select(-purchase) %>%
  colnames()

# compute AVP residuals and SD of fit per feature
avp_list <- lapply(numeric_vars, function(var) {
  other_vars <- setdiff(numeric_vars, var)
  model_y <- glm(as.formula(paste("purchase ~", paste(other_vars, collapse = " + "))),
                 data = sim_data, family = "binomial")
  res_y <- resid(model_y)
  model_x <- lm(as.formula(paste(var, "~", paste(other_vars, collapse = " + "))),
                data = sim_data)
  res_x <- resid(model_x)
  avp_fit <- lm(res_y ~ res_x)
  fit_vals <- predict(avp_fit)
  sd_fit <- sd(fit_vals)
  tibble(
    feature = var,
    res_x = res_x,
    res_y = res_y,
    fit = fit_vals,
    sd_fit = sd_fit
  )
})

# Combine into dataframe
avp_df <- bind_rows(avp_list)

# Order by descending SD
sd_order <- avp_df %>%
  group_by(feature) %>%
  summarise(sd_fit = first(sd_fit)) %>%
  arrange(desc(sd_fit))

avp_df$feature <- factor(avp_df$feature, levels = sd_order$feature)

# Plot 
ggplot(avp_df, aes(x = res_x, y = res_y)) +
  geom_point(alpha = 0.4) +
  geom_smooth(method = "lm", color = "blue", linewidth = 0.8) +
  facet_wrap(~ feature, scales = "free_x") +
  labs(
    title = "Added Variable Plots",
    x = "Feature residual (unexplained by other predictors)",
    y = "Purchase residual (unexplained by other predictors)"
  ) +
  theme_minimal()
```


After considering all additional factors in the logistic regression model, the AVPs suggests the marginal influence of each predictor on the binary response variable purchase. Every panel displays the residual of a specified characteristic (also adjusted for other variables) plotted against the residual of purchase (after eliminating the influence of other predictors). A prominent linear trend in the graphic indicates that the related predictor significantly affects the model.

The graphs reveal that `category_count` has a substantial negative linear correlation with the response residuals, suggesting a notable negative link with the likelihood of purchase even after other attributes are controlled. All three variables, `browsing_time`, `clicked_ad`, and `items_in_cart`, show clear positive linear trends consistent with the idea that more browsing, clicks, and cart activity usually raise the probability of purchase. The plot for `previous_purchases` shows a weaker and less clear trend, suggesting its marginal contribution is smaller, which is consistent with its less significant coefficient in the logistic regression we got above at fitting the model. At last, `device_type` would fit its high p-value in the regression summary and may not be as important. These graphs show generally where the linear model fits well and help visually verify the significance of the strongest predictors.


### Partial Dependence Plots

We now look at Partial Dependence Plots (PDPs) to investigate further the marginal influence of each feature throughout its whole range—holding all other variables constant. PDPs assist us to better understand how changes in individual feature values affect the estimated purchase probability of the model and are especially good for visualising possible nonlinear connections.

```{r}
# numeric variables (excluding target)
numeric_vars <- sim_data %>%
  select(where(is.numeric)) %>%
  select(-purchase) %>%
  colnames()

# Compute PDPs
pdp_list <- lapply(numeric_vars, function(var) {
  pd <- pdp::partial(
    object = log_model,
    pred.var = var,
    train = sim_data,
    prob = TRUE
  )
  colnames(pd) <- c("x", "yhat")  # rename columns
  pd$variable <- var
  return(pd)
})
pdp_df <- bind_rows(pdp_list)

# Compute standard deviation of yhat per variable
sd_order <- pdp_df %>%
  group_by(variable) %>%
  summarise(sd_yhat = sd(yhat)) %>%
  arrange(desc(sd_yhat))

# Reorder variable levels for facet_wrap
pdp_df$variable <- factor(pdp_df$variable, levels = sd_order$variable)

# Prepare rug data (long format)
rug_df <- sim_data %>%
  select(all_of(numeric_vars)) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "x")
rug_df$variable <- factor(rug_df$variable, levels = sd_order$variable)

# Final PDP plot with rug
ggplot(pdp_df, aes(x = x, y = yhat)) +
  geom_line(color = "blue", linewidth = 0.9) +
  geom_rug(data = rug_df, aes(x = x), 
           sides = "b", color = "red", alpha = 0.2, inherit.aes = FALSE) +
  facet_wrap(~ variable, scales = "free_x") +
  labs(title = "PDP - Logistic",
       x = "Feature Value") +
  theme_minimal()
```

These plots offer valuable insights into model behavior and feature effects. Starting with     `category_count`, we see a significant negative nonlinear association with purchase probability, those who browse several product categories are less likely to convert. Users lazily perusing several sorts of products may show decision weariness or a lack of buying intent. On the other hand, `browsing_time` reveals a consistent and obvious upward trend suggesting that people who spend more time on the website are more likely to buy. This probably indicates more involvement and thought. Likewise, `items_in_cart` is strongly positively correlated with purchase likelihood, hence supporting the idea that consumers with more items in their cart are nearer to complete the purchase. `clicked_ad` shows a positive increase in likelihood, implying that ad-clicking activity is a significant indicator of conversion intention. Finally, `past_purchases` reveals a little upward slope, which consistent with usual buyer retention trends, returning consumers are somewhat more inclined to buy again.


### LIME 

Based on the results from the model and the two types of plots we have already generated, we have gained insight into the overall influence and trends of each individual feature on the predicted purchase probability. However, although we can gain the insights through these two plots we have already used, they fail to explain why a specific instance received its particular prediction. To address this limitation, we apply LIME, which provides localized explanations for individual predictions by approximating the model’s behavior near a given instance using a simple, interpretable model. By doing so, LIME allows us to uncover which specific features drove the prediction for each user, and in what direction. Here we choose to analysis the first three observation as our instance and perform the LIME plot on them.
```{r, message = FALSE, warning = FALSE}
set.seed(5293)
sim_data$purchase <- as.factor(sim_data$purchase)

model_type.glm <- function(x, ...) 'classification'
predict_model.glm <- function(x, newdata, type, ...) {
  preds <- predict(x, newdata = newdata, type = "response")
  data.frame(`1` = preds, `0` = 1 - preds)
}

# test train split(choose the first three observations as our instances) 
test_data <- sim_data[1:3, ]          
train_data <- sim_data[-(1:3), ]      

# Fit logistic regression on training data
log_model <- glm(purchase ~ ., data = train_data, family = "binomial")

# explainer
explainer <- lime::lime(
  x = train_data %>% select(-purchase),
  model = log_model,
  bin_continuous = TRUE
)

# Perform LIME on the test instances
explanation <- lime::explain(
  x = test_data %>% select(-purchase),
  explainer = explainer,
  n_labels = 1,
  n_features = 3
)
print(explanation)
plot_features(explanation)
```
  - For case 1: The model correctly predicted no purchase, supported by short browsing time, moderate category count, and an low number of product or empty cart. However, the low Explanation Fit (0.13) means the local linear approximation by LIME does not well represent the model’s decision function in this region.
  - For case 2: Although the user had a short browsing time, the moderate number of items in cart and narrow category exploration were enough to strongly suggest a purchase, which is different from the ground truth. This might means that two strong positive features outweighed one weak negative, but perhaps over-optimistically.
  - For case 3: This prediction is correct that despite low cart items and short browsing time, the narrow category range played a dominant supporting role, leading to a correct purchase prediction.
  


## Non-Linear Model
Based on the result we got previously from the linear model, we now aim to further investigate some more flexible model. Although the linear model gave us a strong basis and let us understand the patterns and individual feature contributions, it is naturally constrained in its capacity to capture non-linear interactions between variables. Hence we trained a Random Forest mode, which build many decision trees and combining their results, to helps us to explore the interaction effects and they can capture complex, non-linear relationships and interactions between variables. Furthermore, Random Forest is still compatible with interpretation tools like as Permutation Importance, PDP, and LIME, hence allowing a consistent and understandable analysis across modelling techniques.

### Fit the Random Forest Model

We trained the model on the same dataset as the linear models, `sim_data`, and fit the model by buliding 100 decision trees with randomly choose two variables at every split. To assist further interpretation, the model also monitors variable relevance.
```{r, message = FALSE, warning = FALSE}
library(randomForest)
# Fit the random forest model
rf_model <- randomForest(
  purchase ~ .,
  data = sim_data,
  ntree = 100,
  importance = TRUE
)

# View model summary
print(rf_model)
```
Based on the summary result of the model we trained, the Out-of-Bag (OOB) error estimate is 25%, indicating that about 75% of observations were accurately predicted on average by the ensemble. The confusion matrix also shows class-specific errors: a 32% misclassification rate for class no purchase and a 20% misclassification rate for purchase.


For the AVPs, while are useful tools for linear models, they are not suitable for non-linear models like Random Forests. This is because AVPs are based on the assumption of linear additivity that they visualize the marginal effect of one predictor on the response after adjusting for others in a linear regression setting. Hence, we rely on the other two plots, PDP and LIME, to interpret non-linear models more appropriately.

### Partial Dependence Plots
In non-linear models, PDPs help us to better understand how each feature influences the projections of our non-linear model. Even when the model incorporates complex, non-linear interactions, this allows us to see the marginal influence of every variable.
```{r, message = FALSE, warning = FALSE}
# Extract numeric variables from sim_data
num_vars <- sim_data %>%
  select(where(is.numeric)) %>%
  colnames()

# Prepare rug data for plotting
rug_df <- sim_data %>%
  select(all_of(num_vars)) %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "x")

# Create PDPs for each numeric feature
pdp_list_rf <- lapply(num_vars, function(var) {
  pd <- pdp::partial(
    object = rf_model,
    pred.var = var,
    train = sim_data,
    prob = TRUE
  )
  names(pd)[1] <- "x"
  pd$variable <- var
  pd
})

# Combine into single data frame
pdp_df_rf <- bind_rows(pdp_list_rf)

# Sort variables by standard deviation
sd_order <- pdp_df_rf %>%
  group_by(variable) %>%
  summarise(sd_yhat = sd(yhat)) %>%
  arrange(desc(sd_yhat))

# Reorder for plotting
pdp_df_rf$variable <- factor(as.character(pdp_df_rf$variable),
                             levels = as.character(sd_order$variable))
rug_df$variable <- factor(as.character(rug_df$variable),
                          levels = as.character(sd_order$variable))

# Plot
library(ggplot2)
ggplot(pdp_df_rf, aes(x = x, y = yhat)) +
  geom_line(color = "blue", linewidth = 0.7) +
  geom_rug(data = rug_df, aes(x = x), color = "red", alpha = 0.2, inherit.aes = FALSE) +
  facet_wrap(~ variable, scales = "free_x") +
  labs(title = "PDP – Random Forest",
       x = "Feature Value") +
  theme_minimal()
```
Based on the result from PDP plots, which we plot then in descending standard deviation order, we analysis their trends case by case. 

`category_count`: it shows a stong upward trend, suggesting that consumers who explore more product categories are considerably more likely to buy, probably because of more involvement or interest. `browsing_time` reveals an inverted U-shaped correlation, which means the probability of purchasing rises first but falls significantly after 2.5–3 hours, implying that prolonged browsing could indicate not purchase rather than buying. `clicked_ad` shows a negative linear trend as well, suggesting that people who click on advertising are really less likely to purchase. Likewise, `items_in_cart` has a significant negative slope that could suggest more items in the cart correspond to lower purchase probability. Lastly, `previous_purchases` presents a slight negative effect, suggesting that users with previous purchases show a slightly lower probability of purchasing again. 


### LIME
Similar as for Linear model, we also perform the LIME to capture the important features for each case in our test set(the first three observations).
```{r, message = FALSE, warning = FALSE}
set.seed(5293)
model_type.randomForest <- function(x, ...) 'classification'

# Train Random Forest model
rf_model <- randomForest(purchase ~ ., data = train_data, ntree = 100)

explainer_rf <- lime(
  x = train_data %>% select(-purchase),
  model = rf_model,
  bin_continuous = TRUE
)
explanation_rf <- explain(
  x = test_data %>% select(-purchase),
  explainer = explainer_rf,
  n_labels = 1,
  n_features = 3  # top 3 features per instance
)
plot_features(explanation_rf)

```
  - For case 1: The model correctly predicted a non-purchase with 69% probability. Features like having 1 or less goods in the basket, a moderate browsing time (between 2.26 and 2.99), and a mid-range category count all helped to support this mainly since they all harmed the purchase probability.
  - For case 2: The model wrongly predicted a purchase with 85% probability. Two features (low category count and moderate items in cart) support the purchase prediction. Short browsing time slightly contradicts it, but overall, the model predicts purchase.
  - For case 3: The model correctly predicts purchase, with 76% probability, mainly due to low category count, but two features pull against that. The moderate fit suggests the explanation is reasonably reliable.


### Model Evaluation
To better understand the overall contribution of each feature to the prediction accuracy of the Random Forest model, we apply permutation importance. For each variables, we randomly shuffling its values and observing the changes in result in model performance. The idea is that if shuffling a feature substantially decreases the accuracy, that feature must be important for the model. For the robustness, we also calculate the $90%$ confidence interval.
```{r}
# Set seed
set.seed(5293)

# Train the model
rf_model <- randomForest(as.factor(purchase) ~ ., data = sim_data)

# Run permutation importance 30 times
perm_list <- replicate(
  30,
  vi_permute(
    object = rf_model,
    feature_names = setdiff(names(sim_data), "purchase"),
    train = sim_data,
    target = "purchase",
    metric = "accuracy",
    nsim = 1,
    pred_wrapper = function(object, newdata) {
      predict(object, newdata = newdata, type = "response")
    }
  ),
  simplify = FALSE
)

# Combine results
raw_long <- bind_rows(perm_list, .id = "rep")

# Compute 90% percentile-based CI
ci_bounds <- raw_long %>%
  group_by(Variable) %>%
  summarise(
    mean = mean(Importance),
    lower = quantile(Importance, 0.05),
    upper = quantile(Importance, 0.95),
    .groups = "drop"
  )

```

```{r}
ggplot(raw_long, aes(x = Importance, y = reorder(Variable, Importance))) +
  geom_jitter(size = 1, height = 0.3, alpha = 0.6) +
  geom_errorbarh(
    data = ci_bounds,
    mapping = aes(xmin = lower, xmax = upper, y = reorder(Variable, mean)),
    inherit.aes = FALSE, 
    height = 0.2,
    color = "red",
    linewidth = 0.8
  ) +
  labs(
    title = "Permutation Importance with 90% CI (Percentile Method)",
    x = "Importance",
    y = "Variable"
  ) +
  theme_minimal()

```

Based on the importance plot with the $90%$ as the error bar, we can gain the permutation importance scores. Specifically, `category_count` is the most influential variable, with the highest mean importance and a comparable narrow confidence interval, indicating it consistently contributes to predictive performance. Follow with `browsing_time` and `items_in_cart`, they also show strong importance, meaning the browsing time and the number of items in their cart are also important for predicting purchases. By contrast, `previous_purchases` is the least important, with lowest mean importance, meaning that their influence on the model's predictions is relatively minor. The result from here somehow consist with the result from the AVP of the linear model and the pdp plots from the non-linear models. A more detailed comparsion and analysis will present in the comparsion section.


